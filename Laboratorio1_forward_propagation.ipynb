{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e01f29",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "\n",
    "En este laboratorio, estaremos creando redes neurales desde cero, analizaremos su performance y el uso de formward propagation. Nota: Todas las librerias relacionadas a Deep Learning, ya cuentan con las funciones y procedimientos para la creación de las redes neurales, por tanto, en la practica no sera necesario realizar las redes neurales desde cero.  El enfoque de este laboratorio es ayudarte a comprender el comportamiento de las redes neurales. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe96f28",
   "metadata": {},
   "source": [
    "#### Artificial Neural Networks - Forward Propagation\n",
    "Resumen\n",
    "\n",
    "De la ultima clase, podemos recapitular como es que las redes neurales funcionan y la importancia de tener una función de propagación. Aqui esta una red neural que contiene dos inputs, contine una \"hidden layer\" con dos nodos y su respectiva salida. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441de645",
   "metadata": {},
   "source": [
    "Comencemos por inicializar aleatoriamente los pesos y los sesgos en la red. Tenemos 6 pesos y 3 sesgos, uno para cada nodo en la capa oculta y para cada nodo en la capa de salida. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ccbdbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "weights = np.around(np.random.uniform(size = 6), decimals = 2)\n",
    "biases = np.around(np.random.uniform(size = 3), decimals = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de7bc7",
   "metadata": {},
   "source": [
    "Veamos el resultado generado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "913885bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38 0.52 0.01 0.21 0.03 0.57]\n",
      "[0.28 0.3  0.97]\n"
     ]
    }
   ],
   "source": [
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c634569",
   "metadata": {},
   "source": [
    "Ahora que tenemos los pesos y los sesgos definidos para la red, calculemos la salida para una entrada dada, $x_1$ and $x_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e7b0860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: 0.5 y x2: 0.85\n"
     ]
    }
   ],
   "source": [
    "x_1 = 0.5\n",
    "x_2 = 0.85\n",
    "print(\"x1: {} y x2: {}\".format(x_1,x_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a32d1",
   "metadata": {},
   "source": [
    "Comencemos calculando la suma ponderada de las entradas  $z_{1, 1}$, para el primer nodo de la capa oculta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad4ed8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#z1_1 = x1*w1 + x2*w2 + ... + xn*wn + b\n",
    "z1_1 = x_1 * weights[0] + x_2 * weights[1] + biases[0]\n",
    "z1_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea2526",
   "metadata": {},
   "source": [
    "Ahora, completa la suma de los pesos de los imputs  $z_{1, 2}$, para el segundo nodo de la capa oculta. Asigna el valor a z_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b56fda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4835"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#z1_2 = x1*w1 + x2*w2 + ... + xn*wn + b\n",
    "z1_2 = x_1 * weights[2] + x_2 * weights[3] + biases[1]\n",
    "z1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae5ea33",
   "metadata": {},
   "source": [
    "Imprime la suma de los pesos para z_12.  R[1.0625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "250d8280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4835\n"
     ]
    }
   ],
   "source": [
    "print(z1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8878c7",
   "metadata": {},
   "source": [
    "Ahora, asumiendo una función de activación sigmoid, calculemos la activación del primer nodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3fde8828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7134092502058658\n"
     ]
    }
   ],
   "source": [
    "a1_1 = 1 / (1+np.exp(-z1_1))\n",
    "print(a1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8b3b0",
   "metadata": {},
   "source": [
    "Calcula también la activación del segundo nodo. $a_{1, 2}$, para la capa oculta y asignalo a a_12. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0bec4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6185740074950563\n"
     ]
    }
   ],
   "source": [
    "a1_2 = 1 / (1+np.exp(-z1_2))\n",
    "print(a1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24516964",
   "metadata": {},
   "source": [
    "Imprime el valor de la función de activacion para el segundo nodo. R[0.7432]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ccc61fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6185740074950563\n"
     ]
    }
   ],
   "source": [
    "print(a1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03c3aff",
   "metadata": {},
   "source": [
    "Ahora estas activaciones servirán como entradas a la capa de salida. Entonces, calculemos la suma ponderada de estas entradas al nodo en la capa de salida. Asigna el valor a z_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67dc425a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3439894617783579\n"
     ]
    }
   ],
   "source": [
    "z2 = a1_1 * weights[4] + a1_2 * weights[5] + biases[2]\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38fe6b0",
   "metadata": {},
   "source": [
    "Imprime la suma de los pesos del nodo de salida. R[1.0025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "970b503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3439894617783579\n"
     ]
    }
   ],
   "source": [
    "print(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6be546",
   "metadata": {},
   "source": [
    "Finalmente, muestra la salida de la funcion de activacion del nodo de output layer asignado a a_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1eb429f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7931452414463654\n"
     ]
    }
   ],
   "source": [
    "a2 = 1 / (1 + np.exp(-z2))\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2876f7",
   "metadata": {},
   "source": [
    "### Siguientes pasos\n",
    "Obviamente, las redes neuronales para problemas reales se componen de muchas capas ocultas y muchos más nodos en cada capa. Por lo tanto, no podemos continuar haciendo predicciones utilizando este enfoque tan ineficiente de calcular la suma ponderada en cada nodo y la activación de cada nodo manualmente.\n",
    "\n",
    "Para codificar una forma automática de hacer predicciones, generalicemos nuestra red. Una red general tomaría $n$ entradas, tendría muchas capas ocultas, cada capa oculta tendría $m$ nodos y tendría una capa de salida. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be540c3a",
   "metadata": {},
   "source": [
    "Inicialización de la red\n",
    "Definamos la estructura de la red\n",
    "\n",
    "n = 2 # inputs\n",
    "num_hidden_layers = 2 # hidden layers\n",
    "m = [2, 2] # nodes in each hidden layer\n",
    "num_nodes_output = 1 # nodes in the output layer\n",
    "Ahora que definimos la estructura de la red, sigamos adelante e iniciemos los pesos y los sesgos en la red a números aleatorios. Para poder inicializar los pesos y los sesgos a números aleatorios, necesitaremos importar la libreria Numpy.\n",
    "\n",
    " \n",
    "\n",
    "import numpy as np \n",
    "num_nodes_previous = n \n",
    "network = {} # empty network\n",
    "##### loop through each layer and randomly initialize the weights and biases\n",
    "​\n",
    "for layer in range(num_hidden_layers + 1):     \n",
    "    if layer == num_hidden_layers:     # if output layer \n",
    "        layer_name = 'output'\n",
    "        num_nodes = num_nodes_output\n",
    "    else:                              # not output layer\n",
    "        layer_name = 'layer_{}'.format(layer + 1)\n",
    "        num_nodes = m[layer]\n",
    "    \n",
    "    # initialize weights and biases\n",
    "    network[layer_name] = {}\n",
    "    for node in range(num_nodes):\n",
    "        node_name = 'node_{}'.format(node+1)\n",
    "        network[layer_name][node_name] = {\n",
    "            'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "            'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "        }\n",
    "    \n",
    "    num_nodes_previous = num_nodes\n",
    "    \n",
    "print(network) \n",
    "¡Ahora con el código anterior, podemos inicializar los pesos y los sesgos pertenecientes a cualquier red de cualquier número de capas ocultas y número de nodos en cada capa. Trabajemos en una función para que podamos ejecutar repetidamente todo este código siempre que queramos construir una red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f087724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(num_inputs, num_hidden_layers, num_nodes_hidden, num_nodes_output):\n",
    "    num_nodes_previous = num_inputs \n",
    "    network = {}\n",
    "    for layer in range(num_hidden_layers + 1):\n",
    "        \n",
    "        if layer == num_hidden_layers:\n",
    "            layer_name = 'output' # output layer \n",
    "            num_nodes = num_nodes_output\n",
    "        else:\n",
    "            layer_name = 'layer_{}'.format(layer + 1) # layer a number\n",
    "            num_nodes = num_nodes_hidden[layer] \n",
    "        \n",
    "        # initialize weights and bias \n",
    "        network[layer_name] = {}\n",
    "        for node in range(num_nodes):\n",
    "            node_name = 'node_{}'.format(node+1)\n",
    "            network[layer_name][node_name] = {\n",
    "                'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "                'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "            }\n",
    "    \n",
    "        num_nodes_previous = num_nodes\n",
    "\n",
    "    return network # return the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68e8e8e",
   "metadata": {},
   "source": [
    "### Usa la función anterior, initialize_network, para crear una red con las siguientes caracteristicas:\n",
    "5 inputs\n",
    "\n",
    "3 hidden layers\n",
    "\n",
    "3 nodos en la primera capa, 2 nodos en la segunda capa y 3 nodos en la tercera capa. \n",
    "\n",
    "1 output layer\n",
    "\n",
    "Almacena la red en la variable small_network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b4da9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5 # inputs\n",
    "num_hidden_layers = 3 # hidden layers\n",
    "m = [3, 2, 3] # nodes in each hidden layer\n",
    "num_nodes_output = 1 # nodes in the output layer\n",
    "\n",
    "small_network = initialize_network(n, num_hidden_layers, m, num_nodes_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328de004",
   "metadata": {},
   "source": [
    "#### Calcular la suma pondera\n",
    "La suma ponderada en cada nodo se calcula como el producto escalar de las entradas y los pesos más el sesgo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9791e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_sum(inputs, weights, bias):\n",
    "    return np.sum(inputs * weights) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7977abc2",
   "metadata": {},
   "source": [
    "Generemos 5 entradas que podamos alimentar small_network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f7da7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs to the network are [0.15 0.74 0.26 0.53 0.01]\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12)\n",
    "inputs = np.around(np.random.uniform(size=5), decimals=2)\n",
    "\n",
    "print('The inputs to the network are {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7681d",
   "metadata": {},
   "source": [
    "Usa la función compute_weighted_sum para obtener las sumas ponderadas para el primer nodo de la primera capa oculta R[1.518]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89b04df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2788]\n"
     ]
    }
   ],
   "source": [
    "computed_weight = compute_weighted_sum(inputs, small_network[\"layer_1\"][\"node_1\"][\"weights\"], small_network[\"layer_1\"][\"node_1\"][\"bias\"])\n",
    "print(computed_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c56bad",
   "metadata": {},
   "source": [
    "### Activación del nodo\n",
    "Recuerda que la salida de cada nodo es simplemente una transformación no lineal de la suma ponderada. Usamos funciones de activación para este mapeo. Usemos la función Sigmoid como función de activación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2d75bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_activation(weighted_sum):\n",
    "    return 1.0 / (1.0 + np.exp(-1 * weighted_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9276e0",
   "metadata": {},
   "source": [
    "Usa la función node_activation para obtener la salida del primer nodo en la primer capa oculta. R[1.518]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "778b70bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78224544]\n"
     ]
    }
   ],
   "source": [
    "print(node_activation(computed_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120561e9",
   "metadata": {},
   "source": [
    "### Forward Propagation\n",
    "La construcción de una red neuronal que puede realizar predicciones es juntar todo. Entonces,  hagamos una función que aplique las funciones compute_weighted_sum y node_activation a cada nodo en la red y propague los datos hasta la capa de salida y genere una predicción para cada nodo en la capa de salida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e1eac",
   "metadata": {},
   "source": [
    "#### Pseudo-codigo\n",
    "\n",
    "1. Empezar con capa de inputs\n",
    "2. Calcular la suma ponderada en los nodos de la capa actual.\n",
    "3. Calcular la salida de los nodos de la capa actual.\n",
    "4. Generar la salida de la capa actual para que sea la entrada a la siguiente capa.\n",
    "5. Siguiente capa de la red.\n",
    "6. Repita los pasos 2 a 4 hasta que calculemos la salida de la capa de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9d968710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(network, inputs):\n",
    "    \n",
    "    layer_inputs = list(inputs) \n",
    "    for layer in network:\n",
    "        \n",
    "        layer_data = network[layer]\n",
    "        \n",
    "        layer_outputs = [] \n",
    "        for layer_node in layer_data:\n",
    "        \n",
    "            node_data = layer_data[layer_node]\n",
    "            node_output = node_activation(compute_weighted_sum(layer_inputs, node_data['weights'], node_data['bias']))\n",
    "            layer_outputs.append(np.around(node_output[0], decimals=4))\n",
    "            \n",
    "        if layer != 'output':\n",
    "            print('The outputs of the nodes in hidden layer number {} is {}'.format(layer.split('_')[1], layer_outputs))\n",
    "    \n",
    "        layer_inputs = layer_outputs \n",
    "\n",
    "    network_predictions = layer_outputs\n",
    "    return network_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d2f40f",
   "metadata": {},
   "source": [
    "Utiliza forward_propagate para la red small_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3eff743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the nodes in hidden layer number 1 is [0.7822, 0.6698, 0.8437]\n",
      "The outputs of the nodes in hidden layer number 2 is [0.8937, 0.7655]\n",
      "The outputs of the nodes in hidden layer number 3 is [0.8447, 0.7152, 0.7855]\n",
      "[0.841]\n"
     ]
    }
   ],
   "source": [
    "print(forward_propagate(small_network, inputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
